{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfPKAgCCWSVr"
      },
      "source": [
        "# Image Classification with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi9CnW9oWSWc"
      },
      "source": [
        "## Training on CIFAR10\n",
        "\n",
        "Now we are going to move to something more challenging - CIFAR10. We can reuse most of the code above. Thankfully, CIFAR is also a popular dataset, so we can again make use of a PyTorch convience function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "RTiX7NNXXI34"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dl_test, device='cpu'):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in dl_test:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(dl_test.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
        "        test_loss, correct, len(dl_test.dataset),\n",
        "        100. * correct / len(dl_test.dataset)))"
      ],
      "metadata": {
        "id": "FDwCEXDVXzP_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################################################\n",
        "# TODO: Implement the missing part of the training function. As a loss function we want to use cross entropy\n",
        "# It can be called with F.cross_entropy().\n",
        "# Hint: Pass through the model -> Backpropagate gradients -> Take gradient step\n",
        "#########################################################################\n",
        "\n",
        "def train(model, dl_train, optimizer, epoch, log_interval=100, device='cpu'):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(dl_train):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # first we need to zero the gradient, otherwise PyTorch would accumulate them\n",
        "        optimizer.zero_grad()         \n",
        "        \n",
        "        ##### implement this part #####\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        ###############################\n",
        "\n",
        "        # stats\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(dl_train.dataset),\n",
        "                100. * batch_idx / len(dl_train), loss.item()))\n",
        "\n",
        "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
        "        loss, correct, len(dl_train.dataset),\n",
        "        100. * correct / len(dl_train.dataset)))"
      ],
      "metadata": {
        "id": "SCvFvDlsXy_h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "09edb2a4404c4796a25e08520bc21db4",
            "8233e01794ef4312b7e2325af9cfada6",
            "c93ead14632648288e76a0f2d21f2b38",
            "176aed0cf796431984295cfa1f00a155",
            "1cbfe6973d49412789b4a88f61dec818",
            "c95756bb25b54007ac2572e7c8cfe32b",
            "cdb17dfcaafd42c0bfc5929a09dad075",
            "16519431b54e4e29b78802efb50b37fa",
            "ec3a24f6e13146148caf95a258c5bef2",
            "873b4857b6ed44439821bd552fb30d35",
            "0edd188fc9a149f9987e78ac369be74a"
          ]
        },
        "id": "w436kGKVWSWd",
        "outputId": "a8857868-a583-4757-9ecf-bb5107453546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09edb2a4404c4796a25e08520bc21db4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "ds_train = datasets.CIFAR10(root='./data', train=True, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMUgKP1CWSWd"
      },
      "source": [
        "This dataset is not normalized yet, so we need to calculate the normalization constants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PVn1TtJwWSWe"
      },
      "outputs": [],
      "source": [
        "ims_train = torch.tensor(ds_train.data)\n",
        "ims_train = ims_train.float() / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlUv3sv7WSWe",
        "outputId": "ce6be473-ca34-42ab-b246-180907e34d30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ims_train.std((0,1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K6Xn7GiNWSWf"
      },
      "outputs": [],
      "source": [
        "#########################################################################\n",
        "# TODO: calculate the mean and std of CIFAR\n",
        "# hint: We want the mean and std of the channel dimension, these should\n",
        "# be 3 dimensional\n",
        "#########################################################################\n",
        "mu = torch.mean(ims_train, dim=(0,1,2))\n",
        "std = torch.std(ims_train, dim=(0,1,2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IefcVuxLWSWh",
        "outputId": "55af1cc8-8b1d-4a49-896b-6c274115ba24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.mean(ims_train, dim=(0,1,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAFgOcnnWSWi"
      },
      "source": [
        "For CIFAR we want to make use of data augmentation to improve generalization. You will find all data augmentations data are included in torchvision here:\n",
        "\n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVrmA707WSWj",
        "outputId": "1629b152-ad2c-43b0-8b56-4d794aae309a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 4 # if you encounter some unexpected errors in data loading, try setting `NUM_WORKERS = 0`\n",
        "#########################################################################\n",
        "# TODO: Implement the proper transforms for the training and test dataloaders. \n",
        "# Then build train and test dataloaders with batch size 128 and 4 workers\n",
        "#\n",
        "# Train: \n",
        "# - Apply a random crop with size 32 on a padded version of the image with P=4\n",
        "# - Flip the image horizontally with a probability of 40 %\n",
        "# - Transform to a Tensor\n",
        "# - Normalize with the constants calculated above\n",
        "# Test: \n",
        "# - Transform to a Tensor\n",
        "# - Normalize with the constants calculated above\n",
        "#########################################################################\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(0.4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mu, std)\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mu, std)\n",
        "])\n",
        "\n",
        "ds_train = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
        "ds_test = datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
        "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaQ0P6BGWSWm",
        "outputId": "6baa6827-b501-4d51-8549-bbe37ad48ae0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#########################################################################\n",
        "# TODO: Adapt the definition from the CNN class above to work on CIFAR.\n",
        "# You can copy and run the following prompt for evaluation:\n",
        "# CNN()(torch.randn(1,3,32,32)).shape\n",
        "# It should print 'torch.Size([1, 10])'\n",
        "# Hint: You need to change 2 things. \n",
        "#########################################################################\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=0)\n",
        "        self.maxpool = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "        self.linear1 = nn.Linear(12544, 128)\n",
        "        self.linear2 = nn.Linear(128, 10)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        act_fn = nn.ReLU()\n",
        "        x = act_fn(self.conv1(x))\n",
        "        x = act_fn(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = act_fn(self.linear1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "CNN()(torch.randn(1,3,32,32)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u05mFo-WSWp"
      },
      "source": [
        "### Have fun with GPUs\n",
        "You can already call it a day until this point because we won't grade the rest of the excecise. You can have more fun with the rest :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4j0LwFCWSWp"
      },
      "source": [
        "\n",
        "If you didn't already, move to colab. To use a GPU, follow on the collaboratory menu tabs, \"Runtime\" => \"Change runtime type\" and set it to GPU. Then run the same training loop but now on GPU. \n",
        "\n",
        "It as easy as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdU-52EuWSWq",
        "outputId": "c8042246-1cd6-4039-b897-76f76c505f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.309940\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.051418\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.841943\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.932481\n",
            "\n",
            "Train set: Average loss: 2.0455, Accuracy: 13209/50000 (26.4%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.7654, Accuracy: 3423/10000 (34.230%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.918455\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.007787\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.717237\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.742854\n",
            "\n",
            "Train set: Average loss: 2.0737, Accuracy: 15817/50000 (31.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.7373, Accuracy: 3492/10000 (34.920%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.777696\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.735710\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.662496\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.732178\n",
            "\n",
            "Train set: Average loss: 1.8668, Accuracy: 16376/50000 (32.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.5896, Accuracy: 3975/10000 (39.750%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.770254\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.747254\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.784971\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.972106\n",
            "\n",
            "Train set: Average loss: 1.8151, Accuracy: 17538/50000 (35.1%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.5899, Accuracy: 4248/10000 (42.480%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.786724\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.628044\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.733561\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.915166\n",
            "\n",
            "Train set: Average loss: 1.6742, Accuracy: 18421/50000 (36.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.4406, Accuracy: 4707/10000 (47.070%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.520344\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.797937\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.532887\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.824367\n",
            "\n",
            "Train set: Average loss: 1.4658, Accuracy: 18371/50000 (36.7%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.4777, Accuracy: 4584/10000 (45.840%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.726820\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.614150\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.804838\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.655705\n",
            "\n",
            "Train set: Average loss: 1.5414, Accuracy: 18903/50000 (37.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.4820, Accuracy: 4691/10000 (46.910%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.834949\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.735724\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.733070\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.664084\n",
            "\n",
            "Train set: Average loss: 1.8259, Accuracy: 19789/50000 (39.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.4318, Accuracy: 4810/10000 (48.100%)\n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.784581\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.679353\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 2.056054\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.621444\n",
            "\n",
            "Train set: Average loss: 1.5804, Accuracy: 20128/50000 (40.3%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.3825, Accuracy: 4993/10000 (49.930%)\n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.508916\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.593524\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.614988\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.482157\n",
            "\n",
            "Train set: Average loss: 1.5157, Accuracy: 20467/50000 (40.9%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.4887, Accuracy: 4743/10000 (47.430%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "if device == 'cuda': torch.backends.cudnn.benchmark = True # additional speed up\n",
        "\n",
        "cnn = CNN()\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "cnn = cnn.to(device)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(cnn, dl_train, optimizer, epoch, log_interval=100, device=device)\n",
        "    test(cnn, dl_test, device=device)    \n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsVdKfssWSWq"
      },
      "source": [
        "This should be way faster now. But the true advantage of the GPU is that we can use much bigger models now and still train them in a reasonable amount of time. PyTorch is again very handy. The torchvision library comes with varies state-of-the-art model architectures, some of which you have seen in the lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XMYHpBGzWSWr"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQqs07RYWSWr",
        "outputId": "1912e422-6b89-41a8-aac9-e9a92b82e100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "cnn = resnet18()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP9PJbFMWSWs"
      },
      "source": [
        "Looks scary! But the only thing you need to change to make it work on CIFAR is the last layer.\n",
        "Currently the last layer is:\n",
        "```\n",
        "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
        "```\n",
        "out_features is the number of classes. This models are developed for Imagenet, a dataset with 1000 classes. So this part of the model you need to adapt. Additionally, you need to add a log-softmax layer again, as we us negative log-likelihood as the training criterion. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cVorTCDyWSWt"
      },
      "outputs": [],
      "source": [
        "#########################################################################\n",
        "# TODO: Adapt the Resnet to work on CIFAR\n",
        "#########################################################################\n",
        "class net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(net, self).__init__()\n",
        "        self.linear = nn.Linear(1000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x;\n",
        "\n",
        "cnn = nn.Sequential(resnet18(), net())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB2KAEMjWSWt",
        "outputId": "3287b7dc-e826-4fd7-ec1a-10fabb18df9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# This should print 'torch.Size([16, 10])'\n",
        "cnn(torch.randn(16,3,32,32)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPh-LfekWSWu",
        "outputId": "4fee2c11-9cbe-499c-d611-2c55242dfe8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.426977\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.083240\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.754175\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.605345\n",
            "\n",
            "Train set: Average loss: 1.7354, Accuracy: 13907/50000 (27.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.5982, Accuracy: 4057/10000 (40.570%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.553405\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.515234\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.445565\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.412619\n",
            "\n",
            "Train set: Average loss: 1.5065, Accuracy: 21743/50000 (43.5%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.4685, Accuracy: 4804/10000 (48.040%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.246738\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.254000\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.119495\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.206833\n",
            "\n",
            "Train set: Average loss: 1.3798, Accuracy: 25805/50000 (51.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.2963, Accuracy: 5433/10000 (54.330%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.316514\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.262223\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.296687\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.210429\n",
            "\n",
            "Train set: Average loss: 1.0553, Accuracy: 28687/50000 (57.4%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.1570, Accuracy: 6059/10000 (60.590%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.190549\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.095338\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.965198\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.949264\n",
            "\n",
            "Train set: Average loss: 1.0143, Accuracy: 30739/50000 (61.5%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.1019, Accuracy: 6278/10000 (62.780%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.134100\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.843368\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.183075\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.977334\n",
            "\n",
            "Train set: Average loss: 1.0146, Accuracy: 32285/50000 (64.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.0537, Accuracy: 6291/10000 (62.910%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.721843\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.943599\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.997678\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.969862\n",
            "\n",
            "Train set: Average loss: 0.9927, Accuracy: 33206/50000 (66.4%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.9601, Accuracy: 6711/10000 (67.110%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.986540\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.874708\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.029629\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.714235\n",
            "\n",
            "Train set: Average loss: 1.0881, Accuracy: 34014/50000 (68.0%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.9359, Accuracy: 6742/10000 (67.420%)\n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.912268\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.937597\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.829110\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.012367\n",
            "\n",
            "Train set: Average loss: 0.9547, Accuracy: 34647/50000 (69.3%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8910, Accuracy: 6932/10000 (69.320%)\n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.850488\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.037292\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.963445\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.851147\n",
            "\n",
            "Train set: Average loss: 0.7181, Accuracy: 35120/50000 (70.2%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8999, Accuracy: 6929/10000 (69.290%)\n",
            "\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.914383\n",
            "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.788172\n",
            "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.726893\n",
            "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.786878\n",
            "\n",
            "Train set: Average loss: 0.7748, Accuracy: 35585/50000 (71.2%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.9036, Accuracy: 6939/10000 (69.390%)\n",
            "\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.855936\n",
            "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.837526\n",
            "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.820039\n",
            "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.792623\n",
            "\n",
            "Train set: Average loss: 0.7939, Accuracy: 35910/50000 (71.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8192, Accuracy: 7214/10000 (72.140%)\n",
            "\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.797296\n",
            "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.615482\n",
            "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.722679\n",
            "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.964536\n",
            "\n",
            "Train set: Average loss: 0.7825, Accuracy: 35987/50000 (72.0%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.9358, Accuracy: 6954/10000 (69.540%)\n",
            "\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.809875\n",
            "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.793328\n",
            "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.697563\n",
            "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.641370\n",
            "\n",
            "Train set: Average loss: 0.7638, Accuracy: 36315/50000 (72.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8110, Accuracy: 7232/10000 (72.320%)\n",
            "\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.776236\n",
            "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.606889\n",
            "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.547760\n",
            "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.733199\n",
            "\n",
            "Train set: Average loss: 0.8646, Accuracy: 36690/50000 (73.4%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7699, Accuracy: 7395/10000 (73.950%)\n",
            "\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.871243\n",
            "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.812350\n",
            "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.816815\n",
            "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.764108\n",
            "\n",
            "Train set: Average loss: 0.8088, Accuracy: 36817/50000 (73.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8528, Accuracy: 7145/10000 (71.450%)\n",
            "\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.793215\n",
            "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.652628\n",
            "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.935964\n",
            "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.873161\n",
            "\n",
            "Train set: Average loss: 0.8099, Accuracy: 36919/50000 (73.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8225, Accuracy: 7269/10000 (72.690%)\n",
            "\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.711833\n",
            "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.791566\n",
            "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.654353\n",
            "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.795874\n",
            "\n",
            "Train set: Average loss: 0.7451, Accuracy: 37094/50000 (74.2%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7622, Accuracy: 7392/10000 (73.920%)\n",
            "\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.942350\n",
            "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.626159\n",
            "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.743377\n",
            "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.728298\n",
            "\n",
            "Train set: Average loss: 0.5452, Accuracy: 37249/50000 (74.5%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8380, Accuracy: 7102/10000 (71.020%)\n",
            "\n",
            "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.743780\n",
            "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.735655\n",
            "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.834957\n",
            "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.813315\n",
            "\n",
            "Train set: Average loss: 0.7131, Accuracy: 37358/50000 (74.7%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7975, Accuracy: 7264/10000 (72.640%)\n",
            "\n",
            "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.774749\n",
            "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.728840\n",
            "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.669352\n",
            "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.860042\n",
            "\n",
            "Train set: Average loss: 0.8735, Accuracy: 37434/50000 (74.9%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7764, Accuracy: 7340/10000 (73.400%)\n",
            "\n",
            "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.709433\n",
            "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.633765\n",
            "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.636052\n",
            "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.767040\n",
            "\n",
            "Train set: Average loss: 0.5259, Accuracy: 37549/50000 (75.1%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8080, Accuracy: 7296/10000 (72.960%)\n",
            "\n",
            "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.550567\n",
            "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.763186\n",
            "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.676597\n",
            "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.862953\n",
            "\n",
            "Train set: Average loss: 0.7624, Accuracy: 37744/50000 (75.5%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7911, Accuracy: 7309/10000 (73.090%)\n",
            "\n",
            "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.696201\n",
            "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.609283\n",
            "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.641489\n",
            "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.754128\n",
            "\n",
            "Train set: Average loss: 0.6263, Accuracy: 37938/50000 (75.9%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8066, Accuracy: 7324/10000 (73.240%)\n",
            "\n",
            "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.721355\n",
            "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.712790\n",
            "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.597431\n",
            "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.721542\n",
            "\n",
            "Train set: Average loss: 0.6512, Accuracy: 37889/50000 (75.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8309, Accuracy: 7248/10000 (72.480%)\n",
            "\n",
            "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.862186\n",
            "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.590331\n",
            "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.730981\n",
            "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.661814\n",
            "\n",
            "Train set: Average loss: 0.7451, Accuracy: 37917/50000 (75.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7179, Accuracy: 7507/10000 (75.070%)\n",
            "\n",
            "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.693106\n",
            "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.584240\n",
            "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.881856\n",
            "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.847503\n",
            "\n",
            "Train set: Average loss: 0.5628, Accuracy: 37911/50000 (75.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7978, Accuracy: 7275/10000 (72.750%)\n",
            "\n",
            "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.759018\n",
            "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.632419\n",
            "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.604900\n",
            "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.673105\n",
            "\n",
            "Train set: Average loss: 0.7854, Accuracy: 38026/50000 (76.1%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8925, Accuracy: 7232/10000 (72.320%)\n",
            "\n",
            "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.634944\n",
            "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.712393\n",
            "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.793679\n",
            "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.563782\n",
            "\n",
            "Train set: Average loss: 0.7494, Accuracy: 38310/50000 (76.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7057, Accuracy: 7627/10000 (76.270%)\n",
            "\n",
            "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.934504\n",
            "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.828742\n",
            "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.819138\n",
            "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.865225\n",
            "\n",
            "Train set: Average loss: 0.6679, Accuracy: 38269/50000 (76.5%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6977, Accuracy: 7613/10000 (76.130%)\n",
            "\n",
            "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.655963\n",
            "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.814333\n",
            "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.693840\n",
            "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.704153\n",
            "\n",
            "Train set: Average loss: 0.9320, Accuracy: 38210/50000 (76.4%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7469, Accuracy: 7464/10000 (74.640%)\n",
            "\n",
            "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.528199\n",
            "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.703757\n",
            "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.706432\n",
            "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.774633\n",
            "\n",
            "Train set: Average loss: 0.6991, Accuracy: 38293/50000 (76.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7442, Accuracy: 7484/10000 (74.840%)\n",
            "\n",
            "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.619149\n",
            "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.795519\n",
            "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.653177\n",
            "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.717995\n",
            "\n",
            "Train set: Average loss: 0.6462, Accuracy: 38419/50000 (76.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8728, Accuracy: 7129/10000 (71.290%)\n",
            "\n",
            "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.747033\n",
            "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.607920\n",
            "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.645377\n",
            "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.591454\n",
            "\n",
            "Train set: Average loss: 0.8038, Accuracy: 38422/50000 (76.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.8314, Accuracy: 7390/10000 (73.900%)\n",
            "\n",
            "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.775816\n",
            "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.649709\n",
            "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.698187\n",
            "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.611629\n",
            "\n",
            "Train set: Average loss: 0.6153, Accuracy: 38352/50000 (76.7%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7752, Accuracy: 7404/10000 (74.040%)\n",
            "\n",
            "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.836904\n",
            "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.718173\n",
            "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.731979\n",
            "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.698766\n",
            "\n",
            "Train set: Average loss: 0.6547, Accuracy: 38568/50000 (77.1%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7455, Accuracy: 7452/10000 (74.520%)\n",
            "\n",
            "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.765939\n",
            "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.740257\n",
            "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.676444\n",
            "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.664005\n",
            "\n",
            "Train set: Average loss: 0.5972, Accuracy: 38410/50000 (76.8%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6557, Accuracy: 7760/10000 (77.600%)\n",
            "\n",
            "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.819240\n",
            "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.643236\n",
            "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.645215\n",
            "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.610366\n",
            "\n",
            "Train set: Average loss: 0.6219, Accuracy: 38640/50000 (77.3%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7753, Accuracy: 7337/10000 (73.370%)\n",
            "\n",
            "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.524496\n",
            "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.620011\n",
            "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.783443\n",
            "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.809309\n",
            "\n",
            "Train set: Average loss: 0.5665, Accuracy: 38789/50000 (77.6%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7631, Accuracy: 7439/10000 (74.390%)\n",
            "\n",
            "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.557138\n",
            "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.608293\n",
            "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.574784\n",
            "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.685221\n",
            "\n",
            "Train set: Average loss: 0.6846, Accuracy: 38701/50000 (77.4%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7210, Accuracy: 7536/10000 (75.360%)\n",
            "\n",
            "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.618409\n",
            "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.688018\n",
            "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.843480\n",
            "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.646097\n",
            "\n",
            "Train set: Average loss: 0.8722, Accuracy: 38667/50000 (77.3%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7569, Accuracy: 7485/10000 (74.850%)\n",
            "\n",
            "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.736543\n",
            "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.602235\n",
            "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.647777\n",
            "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.584764\n",
            "\n",
            "Train set: Average loss: 0.7135, Accuracy: 38727/50000 (77.5%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7003, Accuracy: 7641/10000 (76.410%)\n",
            "\n",
            "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.601613\n",
            "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.623917\n",
            "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.597536\n",
            "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.824298\n",
            "\n",
            "Train set: Average loss: 0.9612, Accuracy: 38765/50000 (77.5%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6884, Accuracy: 7668/10000 (76.680%)\n",
            "\n",
            "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.716984\n",
            "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.554888\n",
            "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.662438\n",
            "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.680841\n",
            "\n",
            "Train set: Average loss: 0.6228, Accuracy: 38848/50000 (77.7%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7401, Accuracy: 7537/10000 (75.370%)\n",
            "\n",
            "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.654515\n",
            "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.705510\n",
            "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.746894\n",
            "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.714885\n",
            "\n",
            "Train set: Average loss: 0.6699, Accuracy: 38964/50000 (77.9%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7714, Accuracy: 7448/10000 (74.480%)\n",
            "\n",
            "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.631383\n",
            "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.727634\n",
            "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.767775\n",
            "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.642888\n",
            "\n",
            "Train set: Average loss: 0.5599, Accuracy: 38927/50000 (77.9%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7212, Accuracy: 7525/10000 (75.250%)\n",
            "\n",
            "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.583978\n",
            "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.592548\n",
            "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.725318\n",
            "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.614788\n",
            "\n",
            "Train set: Average loss: 0.6772, Accuracy: 39104/50000 (78.2%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7168, Accuracy: 7599/10000 (75.990%)\n",
            "\n",
            "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.579796\n",
            "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.636709\n",
            "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.730611\n",
            "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.721382\n",
            "\n",
            "Train set: Average loss: 0.7335, Accuracy: 39139/50000 (78.3%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7589, Accuracy: 7504/10000 (75.040%)\n",
            "\n",
            "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.713583\n",
            "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.599672\n",
            "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.516383\n",
            "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.554843\n",
            "\n",
            "Train set: Average loss: 0.3863, Accuracy: 39080/50000 (78.2%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6573, Accuracy: 7789/10000 (77.890%)\n",
            "\n",
            "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.618206\n",
            "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.513871\n",
            "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.765189\n",
            "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.512962\n",
            "\n",
            "Train set: Average loss: 0.6616, Accuracy: 39072/50000 (78.1%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.6935, Accuracy: 7677/10000 (76.770%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "if device == 'cuda': torch.backends.cudnn.benchmark = True # this gives us additional speed up\n",
        "\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "cnn = cnn.to(device)\n",
        "\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(cnn, dl_train, optimizer, epoch, log_interval=100, device=device)\n",
        "    test(cnn, dl_test, device=device)    \n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysqFWYY-WSWu"
      },
      "source": [
        "This should get us well above 75%, the best we got was ~ 80%.\n",
        "\n",
        "Now, use different torchvision architectures, different optimizers (Adam is always a good choice), data augmentation techniques, and hyperparameter search to achieve a test accuracy of >90 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYEVhFw0WSWv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "d268b61a0efacafa8645774cb6d0204c9f01d7563ef03f7672146d044e8f345c"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09edb2a4404c4796a25e08520bc21db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8233e01794ef4312b7e2325af9cfada6",
              "IPY_MODEL_c93ead14632648288e76a0f2d21f2b38",
              "IPY_MODEL_176aed0cf796431984295cfa1f00a155"
            ],
            "layout": "IPY_MODEL_1cbfe6973d49412789b4a88f61dec818"
          }
        },
        "8233e01794ef4312b7e2325af9cfada6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c95756bb25b54007ac2572e7c8cfe32b",
            "placeholder": "",
            "style": "IPY_MODEL_cdb17dfcaafd42c0bfc5929a09dad075",
            "value": "100%"
          }
        },
        "c93ead14632648288e76a0f2d21f2b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16519431b54e4e29b78802efb50b37fa",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec3a24f6e13146148caf95a258c5bef2",
            "value": 170498071
          }
        },
        "176aed0cf796431984295cfa1f00a155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_873b4857b6ed44439821bd552fb30d35",
            "placeholder": "",
            "style": "IPY_MODEL_0edd188fc9a149f9987e78ac369be74a",
            "value": " 170498071/170498071 [00:14&lt;00:00, 13301263.30it/s]"
          }
        },
        "1cbfe6973d49412789b4a88f61dec818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c95756bb25b54007ac2572e7c8cfe32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb17dfcaafd42c0bfc5929a09dad075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16519431b54e4e29b78802efb50b37fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3a24f6e13146148caf95a258c5bef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "873b4857b6ed44439821bd552fb30d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edd188fc9a149f9987e78ac369be74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}